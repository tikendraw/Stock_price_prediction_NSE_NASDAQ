{"cells":[{"cell_type":"markdown","metadata":{"id":"6NlX8xyOuAa9"},"source":["# Stock Price Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L0fSKJpf1_FJ"},"outputs":[],"source":["# import modules\n","from datetime import datetime\n","!pip install yfinance --quiet\n","import yfinance as yf\n","import matplotlib.pyplot as plt\n","import datetime\n","import time\n","from pandas_datareader import data as pdr\n","import yfinance as yf\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, optimizers, losses, callbacks\n","from tensorflow.keras.preprocessing.sequence import  TimeseriesGenerator\n","import pandas as pd\n","import numpy as np\n","import os "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hRzsFJJ2NF8x"},"outputs":[],"source":["main_path = os.getcwd()\n","print(main_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hUPehKjH6aVZ"},"outputs":[],"source":["def get_stock_symbols():\n","    '''\n","    get stock symbols from NASDAQ and Indian Stock Market\n","\n","    '''\n","    \n","    try:\n","        # getting the stock symbols of Indian Companies\n","        indian_stock_symbols = pd.read_html('https://indiancompanies.in/listed-companies-in-nse-with-symbol/')[0]\n","\n","        #making first row as header /column names\n","        indian_stock_symbols.columns = indian_stock_symbols.iloc[0]\n","        indian_stock_symbols = indian_stock_symbols[1:]\n","\n","        #Saving file\n","        indian_stock_symbols.to_csv('indian_stock_symbols.csv')\n","\n","        # Nasdaq requires manual downloaing\n","        ## nasdaq_url = 'https://www.nasdaq.com/market-activity/stocks/screener'\n","\n","        # Moving csv to src folder\n","        if  os.path.exists(os.path.join(main_path,'src')):\n","            pass\n","        else:\n","            os.makedirs('src')\n","\n","            \n","        os.system('mv -f indian_stock_symbols.csv src/indian_stock_symbols.csv ')\n","\n","    except Exception as e:\n","        print(e,' shit!!!')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YIDt16lRGN7e"},"outputs":[],"source":["#updating the list\n","get_stock_symbols()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MpR8_9DoIlSY"},"outputs":[],"source":["# os.system('rm -rf src')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5rQIVZ_8Lt_o"},"outputs":[],"source":["# creating data path and Moving downloaded files\n","if not os.path.exists(os.path.join(main_path,'data')):\n","    os.makedirs('data')\n","\n","comp1 = 'AAPL'\n","\n","Hist = 5\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"BRATN-8CPMd3"},"outputs":[],"source":["companies = [comp1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"o6GaoofjLyU-"},"outputs":[{"name":"stdout","output_type":"stream","text":["\r[*********************100%***********************]  1 of 1 completed\n"]}],"source":["companies_data = {}\n","for comp in companies:\n","    yf.pdr_override() # \u003c== that's all it takes :-)\n","\n","    # download dataframe\n","    years = 5\n","    end_date = str(datetime.date.today()) # today\n","    start_date = str(datetime.date.today() - datetime.timedelta(days= years*365)) # some years from now\n","    \n","    data = pdr.get_data_yahoo(comp, start=start_date, end=end_date)\n","    companies_data[comp]=data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kqtLZ_DhQgt8"},"outputs":[],"source":["df = companies_data['AAPL']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Nw3rhtnKSZm9"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-c2ec8f1f-92a0-4fc7-b9d9-18c10575fba6\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eOpen\u003c/th\u003e\n","      \u003cth\u003eHigh\u003c/th\u003e\n","      \u003cth\u003eLow\u003c/th\u003e\n","      \u003cth\u003eClose\u003c/th\u003e\n","      \u003cth\u003eAdj Close\u003c/th\u003e\n","      \u003cth\u003eVolume\u003c/th\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003eDate\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2022-09-19\u003c/th\u003e\n","      \u003ctd\u003e149.309998\u003c/td\u003e\n","      \u003ctd\u003e154.559998\u003c/td\u003e\n","      \u003ctd\u003e149.100006\u003c/td\u003e\n","      \u003ctd\u003e154.479996\u003c/td\u003e\n","      \u003ctd\u003e154.479996\u003c/td\u003e\n","      \u003ctd\u003e81474200\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2022-09-20\u003c/th\u003e\n","      \u003ctd\u003e153.399994\u003c/td\u003e\n","      \u003ctd\u003e158.080002\u003c/td\u003e\n","      \u003ctd\u003e153.080002\u003c/td\u003e\n","      \u003ctd\u003e156.899994\u003c/td\u003e\n","      \u003ctd\u003e156.899994\u003c/td\u003e\n","      \u003ctd\u003e107689800\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2022-09-21\u003c/th\u003e\n","      \u003ctd\u003e157.339996\u003c/td\u003e\n","      \u003ctd\u003e158.740005\u003c/td\u003e\n","      \u003ctd\u003e153.600006\u003c/td\u003e\n","      \u003ctd\u003e153.720001\u003c/td\u003e\n","      \u003ctd\u003e153.720001\u003c/td\u003e\n","      \u003ctd\u003e101696800\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2022-09-22\u003c/th\u003e\n","      \u003ctd\u003e152.380005\u003c/td\u003e\n","      \u003ctd\u003e154.470001\u003c/td\u003e\n","      \u003ctd\u003e150.910004\u003c/td\u003e\n","      \u003ctd\u003e152.740005\u003c/td\u003e\n","      \u003ctd\u003e152.740005\u003c/td\u003e\n","      \u003ctd\u003e86652500\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2022-09-23\u003c/th\u003e\n","      \u003ctd\u003e151.190002\u003c/td\u003e\n","      \u003ctd\u003e151.470001\u003c/td\u003e\n","      \u003ctd\u003e148.559998\u003c/td\u003e\n","      \u003ctd\u003e150.429993\u003c/td\u003e\n","      \u003ctd\u003e150.429993\u003c/td\u003e\n","      \u003ctd\u003e95939200\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2ec8f1f-92a0-4fc7-b9d9-18c10575fba6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-c2ec8f1f-92a0-4fc7-b9d9-18c10575fba6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c2ec8f1f-92a0-4fc7-b9d9-18c10575fba6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                  Open        High         Low       Close   Adj Close  \\\n","Date                                                                     \n","2022-09-19  149.309998  154.559998  149.100006  154.479996  154.479996   \n","2022-09-20  153.399994  158.080002  153.080002  156.899994  156.899994   \n","2022-09-21  157.339996  158.740005  153.600006  153.720001  153.720001   \n","2022-09-22  152.380005  154.470001  150.910004  152.740005  152.740005   \n","2022-09-23  151.190002  151.470001  148.559998  150.429993  150.429993   \n","\n","               Volume  \n","Date                   \n","2022-09-19   81474200  \n","2022-09-20  107689800  \n","2022-09-21  101696800  \n","2022-09-22   86652500  \n","2022-09-23   95939200  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df.tail()"]},{"cell_type":"markdown","metadata":{"id":"U06ofCTr7r4U"},"source":["## Creating dataset"]},{"cell_type":"markdown","metadata":{"id":"smr-3zIj7uSz"},"source":["We need to create a dataset that moves with time and creates windows(features) and Horizons(label)\n","\n","1. One to one dataset (One feature column and One Label)\n","    \n","    e.g. feature Adj Close --\u003e Adj Close\n","2. Many to One dataset (All the Features and One Label)\n","    \n","    e.g. [Open, High, Low, Close, Adj Close, Volume] --\u003e Adj Close"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tF50_wfW88Co"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 36.59358597  36.36819077  36.56748581 ... 153.72000122 152.74000549\n"," 150.42999268]\n"]}],"source":["# setting a columns to be predicted\n","wanted = 'Adj Close'\n","price = df[wanted].to_numpy()\n","time = df[wanted].index.to_numpy()\n","\n","# show some prices\n","print(price)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9r_Gi8_IBpE_"},"outputs":[{"data":{"text/plain":["1257"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["len(price)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jB7__vjy9RMp"},"outputs":[],"source":["WINDOW_SIZE = 3\n","HORIZON = 1\n","class WindowMaker:\n","    '''\n","    dataclass returns windows and horizons with given parameter\n","\n","    -------------------\n","    Parameters:\n","        data:nd array       :   numpy array or pandas dataframe\n","        window_size:int     :   size of the window\n","        horizon_size:int    :   size of the horizon\n","\n","        stride:int          :   how much window slides on data\n","        shift:int           :   gap between window and horizon(if needed) \n","\n","    '''\n","    from sklearn.model_selection import train_test_split\n","\n","    def __init__(self, data , window_size:int=7, horizon_size:int=1, label_columns_indices:list=None,label_columns_names:list = None, stride:int = 1, shift:int=0):\n","        self.data = data\n","        self.window_size = window_size\n","        self.horizon_size = horizon_size\n","        self.label_columns_indices = label_columns_indices\n","        self.label_columns_names = label_columns_names\n","        self.stride = stride\n","        self.shift = shift\n","\n","\n","\n","\n","\n","        if type(self.data) == pd.core.frame.DataFrame:\n","\n","            self.column_indices = {name: i for i, name in\n","                                enumerate(self.data.columns)}\n","\n","            if self.label_columns_names is not None:\n","                self.label_columns_indices = [self.column_indices[name]  for name in\n","                                        self.label_columns_names]\n","            \n","            # converting dataframe to ndarray\n","            self.data = self.data.to_numpy()\n","\n","\n","        # create a array of window size\n","        self.window_size_array = np.arange(self.window_size + self.shift + self.horizon_size)\n","\n","        # create array with a forward shift\n","        self.all_array_index = np.arange(len(self.data)- (self.window_size + self.shift + self.horizon_size -1), step = self.stride).reshape(-1,1) + self.window_size_array\n","\n","        # Spliting index in window and horizon\n","        self.all_windows_index = self.all_array_index[:, :self.window_size]\n","        self.all_horizons_index = self.all_array_index[:, self.window_size+self.shift:]\n","\n","\n","        # actuall values of horizon and windows\n","        self.all_windows = self.data[self.all_windows_index]\n","        self.all_horizons_full = self.data[self.all_horizons_index] # contains all the labels\n","\n","        # Work out the label column indices.\n","        if self.label_columns_indices is not None:\n","            self.all_horizons = self.all_horizons_full[...,self.label_columns_indices]\n","        \n","        else:\n","            self.all_horizons = self.all_horizons_full\n","\n","\n","    def make_split(self):\n","        return self.all_windows, self.all_horizons\n","\n","    # returns train, test or train, val, test as tuple\n","    def train_test_val(self,test_size:float = .1, val_size:float = None,random = False, random_state:int = 2):\n","        if random == True:\n","            # creating test data of test_size\n","            if test_size is not None:\n","                xtrain_rest, xtest, ytrain_rest, ytest = train_test_split(self.all_windows, self.all_horizons, test_size = test_size, random_state = random_state)\n","                if val_size is None:\n","                    return (xtrain_rest, ytrain_rest), (xtest, ytest)\n","                if val_size is not None:\n","                    xtrain, xval, ytrain, yval = train_test_split(xtrain_rest, ytrain_rest, test_size = val_size, random_state = random_state)\n","                    return (xtrain, ytrain),( xval, yval), (xtest, ytest)\n","            else:\n","                print('To just create val data use test_size')\n","\n","        else:\n","            # creating test data of test_size\n","            if test_size is not None:\n","                test_len = int(len(self.all_windows)* test_size)\n","                xtrain_rest, xtest, ytrain_rest, ytest = self.all_windows[:-test_len], self.all_windows[-test_len:], self.all_horizons[:-test_len], self.all_horizons[-test_len:]\n","                if val_size is None:\n","                    return (xtrain_rest, ytrain_rest), (xtest, ytest)\n","                if val_size is not None:\n","\n","                    val_len = int(len(xtrain_rest)* val_size)\n","                    xtrain, xval, ytrain, yval = xtrain_rest[:-val_len], xtrain_rest[-val_len:], ytrain_rest[:-val_len], ytrain_rest[-val_len:]\n","                    return (xtrain, ytrain),( xval, yval), (xtest, ytest)\n","            else:\n","                print('To just create val data use test_size')            \n","\n","        \n","\n","    def plot(self, plot_cols:list=None, model = None, figsize = (15,5),**kwargs):\n","        # plots data\n","        plt.figure(figsize = figsize)\n","        plt.grid(True)\n","        for i, name in enumerate(plot_cols):\n","            plt.subplot(len(plot_cols),1, i+1)\n","            plt.plot(self.all_horizons_full[...,self.column_indices[name]], **kwargs)\n","            plt.title(name)\n","            # if model is not None:\n","            #     predictions = model.pred\n","            # plt.plot(self.all_horizons_full[...,self.columns_indices[name]])\n","        plt.show()\n","\n","    def __repr__(self):\n","        return '\\n'.join([\n","                f'Total window size: {self.window_size}',\n","                f'Horizon size: {self.horizon_size}',            # if model is not None:\n","            #     predictions = model.pred\n","            # plt.plot(self.all_horizons_full[...,self.columns_indices[name]])\n","                f'Stride: {self.stride}',\n","                f'Shift: {self.shift}'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"29ZcxaYx1H-L"},"outputs":[],"source":["def compile_and_fit(model, train_data, val_data = None, epochs = 100, patience = 5, verbose = 1, ckpt_verbose = 1):\n","\n","    # callbacks\n","    EarlyStopping = callbacks.EarlyStopping(monitor='mae', patience = patience )\n","\n","    filepath = os.path.join('modelckpt', model.name)\n","\n","    try:\n","        os.makedirs(filepath)\n","    except:\n","        pass\n","\n","    ModelCheckpoint = callbacks.ModelCheckpoint(filepath= filepath,\n","                                                monitor = 'val_loss',\n","                                                verbose = ckpt_verbose,\n","                                                save_best_only = True,\n","                                                save_weights_only = True)\n","    \n","    # compile\n","    model.compile(loss = 'mae',\n","                  optimizer = 'adam',\n","                  metrics = ['mse', 'mae'])\n","    \n","    history = model.fit(train_data, epochs = epochs, \n","                        validation_data= val_data,\n","                        batch_size = 32,\n","                        verbose = verbose,\n","                        callbacks = [ModelCheckpoint])\n","    print('metrics order :Loss, MSE, MAE')\n","    print('Train data Evaluation: ', model.evaluate(train_data))\n","    print('Validation data Evaluation: ',model.evaluate(val_data))\n","    \n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8XDEUw6x4SbH"},"outputs":[],"source":["def pred_plot(model, val_data, figsize = (10,7)):\n","    x= val_data.unbatch().as_numpy_iterator()\n","    yval = [i[1] for i in list(x)]\n","    xval = [i[0] for i in list(x)]\n","\n","    # bigpred = []\n","    print(xval)\n","    ypred = tf.squeeze(model.predict(val_data))\n","\n","    # print(np.arange(1,len(ypred)+1))\n","    #plot it \n","    plt.figure(figsize = figsize)\n","    plt.grid(True)\n","    plt.plot(np.arange(1,len(ypred)+1),yval, marker = 'o', label = 'ytrue')\n","    plt.plot(np.arange(1,len(ypred)+1),ypred, marker = 'x', label = 'ypred')\n","    # plt.ylim(min(price), max(price))\n","\n","    a = np.array(ypred)\n","    b = np.array(yval)\n","\n","    mae = np.mean(np.abs(a-b)) \n","    plt.title(f'mae: {mae}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"oJi59WxwbOo4"},"outputs":[],"source":["# MASE implemented courtesy of sktime - https://github.com/alan-turing-institute/sktime/blob/ee7a06843a44f4aaec7582d847e36073a9ab0566/sktime/performance_metrics/forecasting/_functions.py#L16\n","def mean_absolute_scaled_error(y_true, y_pred):\n","    \"\"\"\n","    Implement MASE (assuming no seasonality of data).\n","    \"\"\"\n","    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n","\n","    # Find MAE of naive forecast (no seasonality)\n","    mae_naive_no_season = tf.reduce_mean(tf.abs(y_true[1:] - y_true[:-1])) # our seasonality is 1 day (hence the shifting of 1 day)\n","\n","    return mae / mae_naive_no_season"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pKL5G85RZgUx"},"outputs":[],"source":["def result(model, test_data):\n","    # Make sure float32 (for metric calculations)\n","    x= test_data.unbatch().as_numpy_iterator()\n","    y_true = [i[1] for i in list(x)]\n","    y_true = tf.cast(y_true, dtype=tf.float32)\n","\n","    y_pred = tf.squeeze(model.predict(test_data))\n","\n","    y_pred = tf.cast(y_pred, dtype=tf.float32)\n","\n","    # Calculate various metrics\n","    mae = tf.keras.metrics.mean_absolute_error(y_true, y_pred)\n","    mse = tf.keras.metrics.mean_squared_error(y_true, y_pred) # puts and emphasis on outliers (all errors get squared)\n","    rmse = tf.sqrt(mse)\n","    mape = tf.keras.metrics.mean_absolute_percentage_error(y_true, y_pred)\n","    mase = mean_absolute_scaled_error(y_true, y_pred)\n","\n","    result =  {\"mae\": mae.numpy(),\n","            \"mse\": mse.numpy(),\n","            \"rmse\": rmse.numpy(),\n","            \"mape\": mape.numpy(),\n","            \"mase\": mase.numpy()}\n","\n","    print(result)\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"2rZGYZ1ggPn-"},"source":["## Spliting the dataset ( Train, Test, Val)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"85gzrThedX2g"},"outputs":[],"source":["wfull = WindowMaker(price, horizon_size=1, label_columns_names = [wanted])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Hnf5Rf0vdXze"},"outputs":[],"source":["windows, horizons = wfull.make_split()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"J7QDXPpae8K1"},"outputs":[],"source":["train_data, val_data = wfull.train_test_val(random_state = 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_8hG4ulWIBYw"},"outputs":[],"source":["train_data = tf.data.Dataset.from_tensor_slices(train_data).batch(32)\n","val_data = tf.data.Dataset.from_tensor_slices(val_data).batch(32)"]},{"cell_type":"markdown","metadata":{"id":"hlCTEq5NV_jl"},"source":["# Model 0: Persistence Algorithm (the “naive” forecast)\n","The most common baseline method for supervised machine learning is the Zero Rule algorithm.\n","\n","This algorithm predicts the majority class in the case of classification, or the average outcome in the case of regression. This could be used for time series, but does not respect the serial correlation structure in time series datasets.\n","\n","The equivalent technique for use with time series dataset is the persistence algorithm.\n","\n","The persistence algorithm uses the value at the previous time step (t-1) to predict the expected outcome at the next time step (t+1).\n","\n","This satisfies the three above conditions for a baseline forecast.\n","\n","To make this concrete, we will look at how to develop a persistence model and use it to establish a baseline performance for a simple univariate time series problem. First, let’s review the Shampoo Sales dataset.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tnJunk6voCm1"},"outputs":[{"data":{"text/plain":["array([[94, 96, 35, 80],\n","       [34, 67, 20, 72],\n","       [ 7, 45,  7, 53],\n","       [50, 72, 17, 19]])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["rand_int = np.random.randint(5,100, (4,1,1,1,4))  \n","rand_int = np.squeeze(rand_int)\n","\n","rand_int"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rXoeOqXwVa06"},"outputs":[{"ename":"SyntaxError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"\u003cipython-input-23-5ec3e735be49\u003e\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"]}],"source":["# Baseline\n","# it just returns a value ahead ( basically predicting the Exact future)\n","\n","# def model0(label_data):\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eN5pK8A-0SRZ"},"outputs":[],"source":["horizons"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6EFr8SlAWmJq"},"outputs":[],"source":["windows.shape, horizons.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LUlYOSeznUyO"},"outputs":[],"source":["val_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"R-DS7gVzWmG2"},"outputs":[],"source":["baseline = Baseline()\n","\n","baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n","                 metrics=[tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n","\n","val_performance = {}\n","performance = {}\n","# val_performance['Baseline'] = baseline.evaluate(val_data)\n","# performance['Baseline'] = baseline.evaluate(train_data, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1Q-RVgobWmEX"},"outputs":[],"source":["pred_plot(baseline, val_data, figsize = (25,15))"]},{"cell_type":"markdown","metadata":{"id":"TakE9OyYznS1"},"source":["# Model 1 : a Dense Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8AYvEXSy1IBT"},"outputs":[],"source":["\n","model1 = keras.Sequential([\n","    layers.Dense(128, activation = 'relu'),\n","    layers.Dense(1)\n","], name = 'model1_dense')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Smtfoz_GESul"},"outputs":[],"source":["compile_and_fit(model1, train_data, val_data,epochs = 200, verbose = 0, ckpt_verbose = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6ODkJl_f5yMs"},"outputs":[],"source":["pred_plot(model1, val_data, figsize = (25,15))"]},{"cell_type":"markdown","metadata":{"id":"Fmf_kkaQI9xD"},"source":["The Graph above shows the comparison between actual points and predicted points only. \n","Note: Predicted prices are not very diffe"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Cwv35AzT8vqD"},"outputs":[],"source":["model1_result = result(model1, val_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mkV5G1zWA257"},"outputs":[],"source":["x= val_data.unbatch().as_numpy_iterator()\n","x=list(x)\n","x[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EjVSojHjJlKc"},"outputs":[],"source":["windows, horizons"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-bICTzxxPoef"},"outputs":[],"source":["test_size = .2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RxT8rhZ8P2FD"},"outputs":[],"source":["test_len = int(len(windows)*test_size)\n","test_len"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"xLRsk498P6Ly"},"outputs":[],"source":["xtrain, xtest, ytrain, ytest = windows[:-test_len], windows[-test_len:], horizons[:-test_len], horizons[-test_len:]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5gmKYjQaQaGg"},"outputs":[],"source":["xtrain.shape, ytrain.shape, xtest.shape, ytest.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iBDe713SQfCZ"},"outputs":[],"source":["windows.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jBxg93zxQ-mN"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPqg3p6bv1a9Qr0uv3NOybU","collapsed_sections":[],"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}